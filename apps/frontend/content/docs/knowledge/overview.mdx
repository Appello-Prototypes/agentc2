---
title: "Knowledge Overview"
description: "RAG pipeline for AI agents: ingest documents, chunk content, embed vectors, store in database, retrieve semantically, and generate responses."
section: "knowledge"
order: 1
primaryKeyword: "RAG pipeline for AI agents"
relatedSlugs:
    [
        "knowledge/document-ingestion",
        "knowledge/vector-search",
        "knowledge/hybrid-search",
        "knowledge/api-reference"
    ]
secondaryKeywords:
    [
        "RAG",
        "retrieval augmented generation",
        "vector search",
        "document ingestion",
        "semantic search"
    ]
pageType: "concept"
ctaLabel: "Launch AgentC2 Workspace"
ctaHref: "/workspace"
---

# Knowledge Overview

Knowledge (RAG - Retrieval Augmented Generation) enables AI agents to access your documents, knowledge base, and internal data. Documents are ingested, chunked, embedded into vectors, stored in PostgreSQL, and retrieved semantically during agent conversations.

## What is knowledge/RAG?

RAG (Retrieval Augmented Generation) combines document storage with semantic search to provide agents with relevant context from your knowledge base. When an agent receives a query, it searches your documents semantically, retrieves relevant chunks, and uses them to generate informed responses.

AgentC2's RAG pipeline handles the entire lifecycle: document ingestion, chunking, embedding, vector storage, semantic retrieval, and response generation.

## Architecture

The RAG pipeline follows a six-stage architecture:

```
Ingest → Chunk → Embed → Store → Retrieve → Generate
   ↓        ↓       ↓       ↓        ↓         ↓
Document  Text   Vector  Database  Semantic  Agent
Content  Chunks  Embed   Storage   Search   Response
```

### 1. Ingest

Documents are ingested via API or UI:

- **Supported formats**: Markdown, text, HTML, JSON, PDF (via extraction)
- **Sources**: Manual upload, API ingestion, web scraping, integrations
- **Metadata**: Category, tags, custom metadata

### 2. Chunk

Documents are split into smaller chunks:

- **Fixed-size**: Fixed character/token limits
- **Semantic**: Chunk at semantic boundaries (sentences, paragraphs)
- **Recursive**: Hierarchical chunking with overlap
- **Metadata**: Each chunk retains document metadata

### 3. Embed

Chunks are embedded into vectors:

- **Model**: OpenAI `text-embedding-3-small` (1536 dimensions)
- **Vector format**: PostgreSQL `vector(1536)` type
- **Batch processing**: Efficient batch embedding

### 4. Store

Vectors are stored in a high-performance vector database:

- **Indexing**: HNSW (Hierarchical Navigable Small World) index for fast similarity search
- **Metadata**: Document ID, chunk index, and source metadata are stored alongside each vector

### 5. Retrieve

Queries are embedded and searched semantically:

- **Similarity metric**: Cosine similarity
- **Top-K retrieval**: Return top K most similar chunks
- **Score filtering**: Filter by minimum similarity score
- **Metadata filtering**: Filter by document category, tags, etc.

### 6. Generate

Retrieved chunks are used to generate responses:

- **Context injection**: Chunks included in agent prompt
- **Citation**: Sources cited in response
- **Streaming**: Real-time response streaming

## When to use knowledge/RAG

RAG is ideal when:

- **Knowledge base access**: Agents need access to internal documentation
- **Domain-specific knowledge**: Agents require specialized domain knowledge
- **Up-to-date information**: Documents can be updated without retraining models
- **Citation requirements**: Responses must cite sources
- **Large document sets**: Too many documents to include in prompt directly

<Callout type="info">
    RAG complements agent memory. Use **memory** for conversation context and **RAG** for document
    knowledge. Agents can use both simultaneously.
</Callout>

## Document properties

Each document you create via the API has the following key properties:

- **`slug`** — A unique, URL-safe identifier (e.g., `product-docs`)
- **`name`** — A human-readable display name
- **`content`** — The document body (markdown, plain text, or HTML)
- **`contentType`** — The format of the content: `"markdown"`, `"text"`, or `"html"`
- **`description`** — An optional summary
- **`category`** / **`tags`** — Used for organizing and filtering documents
- **`metadata`** — Custom key-value metadata

After ingestion, the platform automatically tracks the number of chunks generated and their embedding status. You can query this information via the documents API.

## RAG pipeline flow

### Ingestion

```bash
curl -X POST https://agentc2.ai/agent/api/documents \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "slug": "product-docs",
    "name": "Product Documentation",
    "content": "# Product Guide\n\n...",
    "contentType": "markdown",
    "category": "documentation",
    "tags": ["product", "guide"]
  }'
```

### Automatic processing

After ingestion, the system automatically:

1. **Chunks** the content into semantic chunks
2. **Embeds** chunks into vectors
3. **Stores** vectors in the vector index
4. **Updates** the document's embedding status and chunk count

### Query

```bash
curl -X POST https://agentc2.ai/agent/api/rag/query \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How do I configure the product?",
    "topK": 5,
    "minScore": 0.7
  }'
```

### Response generation

```bash
curl -X POST https://agentc2.ai/agent/api/rag/generate \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How do I configure the product?",
    "maxResults": 5
  }'
```

## Key capabilities

| Capability             | Description                    | Example Use Case                     |
| ---------------------- | ------------------------------ | ------------------------------------ |
| **Document Ingestion** | Upload documents via API or UI | Product docs, knowledge base, FAQs   |
| **Semantic Chunking**  | Intelligent text chunking      | Preserve context across chunks       |
| **Vector Embedding**   | Convert text to embeddings     | Semantic similarity search           |
| **Similarity Search**  | Find relevant chunks           | Retrieve context for queries         |
| **Metadata Filtering** | Filter by category, tags       | Search within specific document sets |
| **Version Control**    | Track document versions        | Update docs without losing history   |
| **Citation**           | Cite sources in responses      | Provide source attribution           |
| **Streaming**          | Real-time response generation  | Low-latency UX                       |

## Integration with agents

Agents can use RAG in two ways:

### 1. RAG tool

Attach RAG as a tool to agents:

```bash
curl -X POST https://agentc2.ai/agent/api/agents/research-agent/tools \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "toolId": "rag-query"
  }'
```

Agents can call the tool during conversations:

```
User: What are the product features?
Agent: [Calls rag-query tool] Based on the documentation...
```

### 2. RAG context injection

Configure agents to automatically inject RAG context:

```bash
curl -X PATCH https://agentc2.ai/agent/api/agents/research-agent \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "ragConfig": {
      "enabled": true,
      "topK": 5,
      "minScore": 0.7,
      "autoInject": true
    }
  }'
```

## Performance considerations

### Embedding

- **Model**: OpenAI `text-embedding-3-small` (1536 dimensions)
- **Latency**: ~100-200ms per batch

### Vector search

- **Similarity**: Cosine similarity
- **Latency**: Under 10ms for top-K search
- **Scalability**: Supports millions of vectors

### Chunking strategy

- **Optimal size**: 500-1000 characters per chunk
- **Overlap**: 50-100 characters for context preservation
- **Boundaries**: Chunk at sentence/paragraph boundaries

## Next steps

- **[Document Ingestion](/docs/knowledge/document-ingestion)** — Learn how to ingest documents
- **[Vector Search](/docs/knowledge/vector-search)** — Understand semantic search
- **[Hybrid Search](/docs/knowledge/hybrid-search)** — Combine semantic and lexical search
- **[Knowledge API Reference](/docs/knowledge/api-reference)** — Complete API documentation
