---
title: "Agent Configuration"
description: "Configure model settings, instructions, temperature, tokens, and advanced options."
section: "agents"
order: 3
primaryKeyword: "AI agent configuration"
relatedSlugs: ["agents/creating-agents", "agents/model-providers", "agents/memory"]
pageType: "reference"
---

# Agent Configuration

Configure your agent's behavior through model settings, instructions, temperature, token limits, and advanced options. All configuration is stored in PostgreSQL and takes effect immediately for all production channels.

## Required fields

Every agent must have these four fields:

| Field           | Type   | Description                                                          |
| --------------- | ------ | -------------------------------------------------------------------- |
| `name`          | string | Display name (e.g., "Customer Support Agent")                        |
| `instructions`  | string | System instructions that define the agent's behavior and personality |
| `modelProvider` | string | `"openai"` or `"anthropic"`                                          |
| `modelName`     | string | Model identifier (e.g., `"gpt-4o"`, `"claude-sonnet-4-20250514"`)    |

Example minimal configuration:

```bash
curl -X POST https://agentc2.ai/agent/api/agents \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Research Assistant",
    "instructions": "You are a research assistant. Search the web for current information and provide well-sourced answers.",
    "modelProvider": "openai",
    "modelName": "gpt-4o"
  }'
```

## Model settings

Control how the LLM generates responses:

### Temperature

Controls randomness in output. Range: `0.0` to `2.0`.

| Value         | Behavior                            | Use Case                                                |
| ------------- | ----------------------------------- | ------------------------------------------------------- |
| `0.0` - `0.3` | Highly deterministic, focused       | Code generation, factual Q&A, data extraction           |
| `0.4` - `0.7` | Balanced creativity and consistency | General conversation, content creation (default: `0.7`) |
| `0.8` - `1.2` | More creative, varied responses     | Creative writing, brainstorming                         |
| `1.3` - `2.0` | Very creative, unpredictable        | Experimental, artistic applications                     |

```bash
curl -X PATCH https://agentc2.ai/agent/api/agents/research-assistant \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "temperature": 0.3
  }'
```

### Max tokens

Maximum tokens in the response. If `null`, uses the model's default (typically 4096-8192 for most models).

```bash
curl -X PATCH https://agentc2.ai/agent/api/agents/research-assistant \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "maxTokens": 2048
  }'
```

<Callout type="warning">
    Setting `maxTokens` too low may truncate responses. For long-form content, use `null` or a high
    value (4096+). Token limits are enforced per-turn, not per-conversation.
</Callout>

## Instructions

The `instructions` field defines the agent's behavior, personality, and constraints. It's sent as the system message to the LLM on every turn.

### Static instructions

Use `instructions` for fixed behavior:

```json
{
    "instructions": "You are a customer support agent. Be empathetic, clear, and solution-oriented. When you cannot resolve an issue, escalate to human support. Never make up information or promise features that don't exist."
}
```

### Templated instructions

Use `instructionsTemplate` with `{{variable}}` placeholders that resolve at runtime via `RequestContext`:

```json
{
    "instructionsTemplate": "You are {{agentName}}, a support agent for {{organizationName}}. Current user: {{userName}} ({{userId}}). Today's date: {{currentDate}}."
}
```

Available template variables:

| Variable               | Source                            | Example                    |
| ---------------------- | --------------------------------- | -------------------------- |
| `{{agentName}}`        | Agent's `name` field              | `"Customer Support Agent"` |
| `{{userId}}`           | `requestContext.userId`           | `"user_123"`               |
| `{{userName}}`         | `requestContext.userName`         | `"John Doe"`               |
| `{{organizationName}}` | `requestContext.organizationName` | `"Acme Corp"`              |
| `{{workspaceId}}`      | `requestContext.workspaceId`      | `"ws_456"`                 |
| `{{currentDate}}`      | Current date (ISO 8601)           | `"2026-02-18"`             |
| `{{currentTime}}`      | Current time (ISO 8601)           | `"2026-02-18T12:00:00Z"`   |

If both `instructions` and `instructionsTemplate` are provided, `instructionsTemplate` takes precedence. The template is resolved at runtime, so you can update it without redeploying code.

<Callout type="tip">
    Use templated instructions for multi-tenant agents where each organization needs personalized
    behavior. The template resolves per-request, enabling dynamic context injection.
</Callout>

## Model configuration

The `modelConfig` JSON field supports provider-specific options:

### OpenAI options

```json
{
    "modelConfig": {
        "toolChoice": "auto",
        "parallelToolCalls": true,
        "reasoningEffort": "medium"
    }
}
```

| Option              | Type    | Values                           | Description                                      |
| ------------------- | ------- | -------------------------------- | ------------------------------------------------ |
| `toolChoice`        | string  | `"auto"`, `"required"`, `"none"` | Control tool usage (`"auto"` = agent decides)    |
| `parallelToolCalls` | boolean | `true`, `false`                  | Allow multiple tool calls in parallel (faster)   |
| `reasoningEffort`   | string  | `"low"`, `"medium"`, `"high"`    | For o1 models: reasoning depth vs speed tradeoff |

### Anthropic options

```json
{
    "modelConfig": {
        "cacheControl": {
            "type": "ephemeral",
            "ttl": 3600
        }
    }
}
```

| Option         | Type   | Description                                                                        |
| -------------- | ------ | ---------------------------------------------------------------------------------- |
| `cacheControl` | object | Response caching configuration (`type`: `"ephemeral"` or `"long"`, `ttl`: seconds) |

### Extended thinking

For models that support extended thinking (e.g., o1, o3):

```json
{
    "modelConfig": {
        "extendedThinking": true,
        "thinkingBudget": 10000
    }
}
```

- `extendedThinking`: Enable extended reasoning mode
- `thinkingBudget`: Maximum tokens for thinking (default: model-specific)

## Max steps

The `maxSteps` field controls how many tool call rounds the agent can make per turn. Default: `5`.

```bash
curl -X PATCH https://agentc2.ai/agent/api/agents/research-assistant \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "maxSteps": 10
  }'
```

| Value       | Behavior                     | Use Case                                |
| ----------- | ---------------------------- | --------------------------------------- |
| `1`         | Single tool call per turn    | Simple Q&A, no multi-step workflows     |
| `3` - `5`   | Moderate tool chaining       | Research, data gathering (default: `5`) |
| `10` - `20` | Complex multi-step reasoning | Analysis, planning, complex workflows   |
| `50`        | Maximum flexibility          | Experimental, research scenarios        |

<Callout type="warning">
    Higher `maxSteps` values increase latency and cost. Each step is a separate LLM call. Use the
    minimum value that supports your use case.
</Callout>

## Complete configuration example

A fully configured agent with all options:

```bash
curl -X POST https://agentc2.ai/agent/api/agents \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Advanced Research Agent",
    "slug": "advanced-research",
    "description": "Research agent with extended thinking and parallel tool calls",
    "instructions": "You are a research assistant. Search multiple sources, synthesize findings, and cite your sources.",
    "instructionsTemplate": "You are {{agentName}}. Current date: {{currentDate}}. User: {{userName}}.",
    "modelProvider": "openai",
    "modelName": "o1-preview",
    "temperature": 0.2,
    "maxTokens": 8192,
    "modelConfig": {
      "toolChoice": "auto",
      "parallelToolCalls": true,
      "extendedThinking": true,
      "thinkingBudget": 15000
    },
    "memoryEnabled": true,
    "memoryConfig": {
      "lastMessages": 30,
      "semanticRecall": {
        "topK": 5,
        "minScore": 0.75
      }
    },
    "maxSteps": 15,
    "tools": ["web-fetch", "calculator", "memory-recall"],
    "scorers": ["quality", "safety", "relevance"]
  }'
```

## Updating configuration

Update any field via `PATCH`:

```bash
curl -X PATCH https://agentc2.ai/agent/api/agents/research-assistant \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "temperature": 0.4,
    "maxSteps": 8
  }'
```

Changes take effect immediately for all production channels (API, Slack, voice, webhooks). No code deployment required.

## Configuration best practices

1. **Start simple** — Begin with defaults, then tune based on observed behavior
2. **Use low temperature for precision** — Research, code, data extraction benefit from `0.2` - `0.4`
3. **Enable parallel tool calls** — Reduces latency when multiple tools are needed
4. **Set appropriate maxSteps** — Match to your use case (5-10 for most scenarios)
5. **Use templated instructions** — For multi-tenant or dynamic contexts
6. **Monitor costs** — Higher `maxSteps` and `maxTokens` increase token usage

## Related topics

- **[Model Providers](/docs/agents/model-providers)** — Compare OpenAI and Anthropic models
- **[Agent Memory](/docs/agents/memory)** — Configure conversation memory and semantic recall
- **[Creating Agents](/docs/agents/creating-agents)** — Learn how to create agents via API or UI
