---
title: "Continuous Learning"
description: "Extract signals from agent runs, generate improvement proposals, and promote changes safely."
section: "agents"
order: 11
primaryKeyword: "AI agent learning"
relatedSlugs: ["agents/evaluations", "agents/version-control"]
pageType: "concept"
---

# Continuous Learning

Continuous learning enables agents to improve themselves automatically by analyzing run traces, extracting signals, generating improvement proposals, and safely promoting changes through A/B experiments and human approval gates. The system observes agent behavior, identifies patterns that indicate suboptimal performance, proposes targeted improvements, and validates changes before deployment.

## The Learning Loop

The continuous learning system follows a closed-loop cycle that transforms observations into actionable improvements:

<Steps>
    <Step title="Observe">
        Collect agent runs and their outcomes. The system tracks every execution, including tool
        calls, LLM responses, evaluation scores, guardrail violations, and user feedback.
    </Step>
    <Step title="Extract Signals">
        Analyze runs to identify patterns that indicate problems: low evaluation scores, tool
        failures, guardrail hits, negative feedback, high latency, errors, or recurring patterns
        across multiple runs.
    </Step>
    <Step title="Generate Proposals">
        Use AI to generate specific improvement proposals based on extracted signals. Proposals can
        modify instructions, add or remove tools, adjust memory configuration, or change model
        settings.
    </Step>
    <Step title="Experiment">
        Run A/B tests comparing the baseline agent version against candidate versions with proposed
        changes. Measure performance improvements using evaluation scorers and success metrics.
    </Step>
    <Step title="Promote">
        After successful experiments, promote winning changes to production. Low-risk changes
        (instruction-only edits) can auto-promote; higher-risk changes require human approval.
    </Step>
</Steps>

<Callout type="info">
    Continuous learning is enabled per-agent via a `LearningPolicy` configuration. By default,
    learning sessions trigger when signal thresholds are exceeded (e.g., 5 low-score signals in 60
    minutes) or on a scheduled basis (every 6 hours).
</Callout>

## LearningSession Model

Each learning cycle is orchestrated by a `LearningSession` that tracks the entire process from signal collection to promotion:

```typescript
interface LearningSession {
    id: string;
    agentId: string;
    status: LearningSessionStatus;
    runCount: number; // Number of runs analyzed
    datasetHash: string; // SHA256 hash for reproducibility
    baselineVersion: number; // Agent version at start
    scorerConfig: object; // Scorer configuration used
    thresholdsJson: object; // Gating thresholds for A/B test
    createdAt: Date;
    completedAt?: Date;
}
```

### Session Status Flow

Learning sessions progress through these statuses:

| Status              | Description                       | Next Actions                           |
| ------------------- | --------------------------------- | -------------------------------------- |
| `COLLECTING`        | Gathering runs for analysis       | Wait for threshold or schedule trigger |
| `ANALYZING`         | Extracting signals from runs      | Process run traces, identify patterns  |
| `PROPOSING`         | Generating improvement proposals  | Create candidate versions with changes |
| `TESTING`           | Running A/B experiments           | Compare baseline vs candidates         |
| `AWAITING_APPROVAL` | Waiting for human approval        | Review proposal, approve or reject     |
| `APPROVED`          | Approved and promoting            | Apply changes to production agent      |
| `PROMOTED`          | Successfully promoted new version | Learning cycle complete                |
| `REJECTED`          | Rejected by human reviewer        | Session ends, no changes applied       |
| `FAILED`            | Failed during processing          | Error logged, session ends             |

## Signal Extraction

Signals are extracted from agent runs by analyzing execution traces, evaluation scores, and user feedback. The system identifies multiple signal types:

### Signal Types

| Signal Type         | Trigger Condition                            | Example                                     |
| ------------------- | -------------------------------------------- | ------------------------------------------- |
| `LOW_SCORE`         | Run scored below threshold                   | Quality score < 0.6                         |
| `TOOL_FAILURE`      | Tool call failed or returned error           | API timeout, invalid response               |
| `GUARDRAIL_HIT`     | Guardrail policy triggered                   | Content filter blocked output               |
| `NEGATIVE_FEEDBACK` | User gave negative feedback                  | Thumbs down, low rating                     |
| `HIGH_LATENCY`      | Run took too long                            | Response time > 5 seconds                   |
| `ERROR`             | Run failed with exception                    | Unhandled error, crash                      |
| `PATTERN`           | Detected pattern across runs                 | Repeated failure on same input type         |
| `SKILL_CORRELATION` | Skill correlated with poor performance       | Tool from skill X fails frequently          |
| `NARRATIVE_PATTERN` | Recurring pattern from AI auditor narratives | "Agent struggles with multi-step reasoning" |

### Starting a Learning Session

Create a new learning session to begin analyzing agent runs:

```bash
curl -X POST https://agentc2.ai/agent/api/agents/research-assistant/learning \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "runCount": 100,
    "fromDate": "2026-02-01T00:00:00Z",
    "toDate": "2026-02-18T23:59:59Z",
    "scorerConfig": {
      "scorers": ["quality", "safety"],
      "thresholds": {
        "quality": 0.7,
        "safety": 0.9
      }
    }
  }'
```

The API returns the session ID and initial status:

```json
{
    "success": true,
    "session": {
        "id": "ls_abc123",
        "agentId": "cm_xyz789",
        "status": "COLLECTING",
        "runCount": 0,
        "baselineVersion": 5,
        "createdAt": "2026-02-18T12:00:00.000Z"
    }
}
```

## Proposal Generation

After signals are extracted, the system generates improvement proposals using AI analysis. Proposals specify concrete changes to improve agent performance:

### Proposal Types

| Proposal Type  | Changes Included               | Risk Tier |
| -------------- | ------------------------------ | --------- |
| `instructions` | Instruction text edits only    | LOW       |
| `tools`        | Add or remove tools            | MEDIUM    |
| `memory`       | Adjust memory configuration    | MEDIUM    |
| `model`        | Change model or model settings | HIGH      |
| `combined`     | Multiple change types          | HIGH      |

### Risk Classification

Proposals are automatically classified by risk tier to determine approval requirements:

| Risk Tier  | Changes Allowed                     | Approval Mode            |
| ---------- | ----------------------------------- | ------------------------ |
| **LOW**    | Instruction-only edits              | Auto-promotion eligible  |
| **MEDIUM** | Tool configuration changes          | Human review recommended |
| **HIGH**   | Model, memory, or guardrail changes | Human approval required  |

Low-risk proposals can be auto-promoted if they pass A/B tests. Medium and high-risk proposals require explicit human approval before promotion.

### Example Proposal

```json
{
    "id": "lp_def456",
    "sessionId": "ls_abc123",
    "proposalType": "instructions",
    "title": "Improve handling of ambiguous queries",
    "description": "Agent struggles when users ask vague questions. Add guidance to ask clarifying questions.",
    "instructionsDiff": "@@ -1,3 +1,5 @@\n You are a research assistant.\n+When users ask ambiguous questions, ask clarifying questions\n+to better understand their needs before searching.\n",
    "expectedImpact": "Reduces low-quality responses by 15%",
    "confidenceScore": 0.82,
    "riskTier": "LOW",
    "autoEligible": true
}
```

## A/B Experiments

Before promoting changes, the system runs A/B experiments comparing the baseline agent version against candidate versions with proposed changes:

### Experiment Configuration

```bash
curl -X POST https://agentc2.ai/agent/api/agents/research-assistant/learning/experiments \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "sessionId": "ls_abc123",
    "proposalId": "lp_def456",
    "testRunCount": 50,
    "successCriteria": {
      "quality": { "min": 0.75, "improvement": 0.05 },
      "safety": { "min": 0.9 }
    }
  }'
```

Experiments run parallel conversations with both versions, comparing:

- **Evaluation scores** (quality, safety, relevance)
- **Success rates** (tool call success, guardrail compliance)
- **Latency** (response time)
- **Cost** (token usage, API costs)

### Experiment Results

```json
{
    "id": "le_ghi789",
    "status": "COMPLETED",
    "baselineVersion": 5,
    "candidateVersion": 6,
    "results": {
        "baseline": {
            "avgQualityScore": 0.72,
            "avgSafetyScore": 0.95,
            "successRate": 0.88,
            "avgLatencyMs": 2340
        },
        "candidate": {
            "avgQualityScore": 0.79,
            "avgSafetyScore": 0.96,
            "successRate": 0.92,
            "avgLatencyMs": 2280
        },
        "improvement": {
            "quality": 0.07,
            "safety": 0.01,
            "successRate": 0.04
        },
        "passed": true
    }
}
```

## Promotion with Guardrails

After successful experiments, proposals are promoted to production. The promotion process includes safety guardrails:

### Auto-Promotion (Low Risk)

Low-risk proposals (instruction-only edits) can auto-promote if they:

1. Pass A/B tests with statistically significant improvements
2. Meet all success criteria thresholds
3. Don't introduce regressions in other metrics

```bash
# Auto-promotion happens automatically after experiment completion
# No API call needed - system promotes eligible proposals
```

### Human Approval (Medium/High Risk)

Medium and high-risk proposals require explicit human approval:

```bash
curl -X POST https://agentc2.ai/agent/api/agents/research-assistant/learning/ls_abc123/approve \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "proposalId": "lp_def456",
    "notes": "Reviewed proposal, looks good. Approved for promotion."
  }'
```

Or reject a proposal:

```bash
curl -X POST https://agentc2.ai/agent/api/agents/research-assistant/learning/ls_abc123/reject \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "proposalId": "lp_def456",
    "reason": "Proposed tool addition conflicts with existing workflow"
  }'
```

<Callout type="warning">
    Promotion creates a new agent version. You can roll back to previous versions if needed using
    the version control system.
</Callout>

## Inngest Event Flow

The learning system uses Inngest for asynchronous event processing. Events flow through the system as follows:

### Event Sequence

1. **`learning/session.start`** — Triggered when a new learning session is created
    - Collects runs matching criteria
    - Creates `LearningDataset` snapshot
    - Transitions to `ANALYZING` status

2. **`learning/signals.extract`** — Extracts signals from collected runs
    - Analyzes run traces, scores, feedback
    - Creates `LearningSignal` records
    - Identifies patterns and correlations
    - Transitions to `PROPOSING` status

3. **`learning/proposals.generate`** — Generates improvement proposals
    - Uses AI to analyze signals and generate proposals
    - Creates `LearningProposal` records with risk classification
    - Builds candidate agent versions
    - Transitions to `TESTING` status

4. **`learning/experiment.run`** — Runs A/B experiments
    - Executes parallel conversations with baseline and candidate
    - Collects metrics and scores
    - Compares results against success criteria
    - Transitions to `AWAITING_APPROVAL` or `APPROVED` status

5. **`learning/approval.request`** — Requests human approval (for medium/high risk)
    - Sends notification to reviewers
    - Waits for approval or rejection
    - On approval, transitions to `APPROVED` status

6. **Promotion** — Applies changes to production agent
    - Creates new agent version
    - Updates agent configuration
    - Transitions to `PROMOTED` status

### Monitoring Learning Sessions

Query learning session status and progress:

```bash
curl https://agentc2.ai/agent/api/agents/research-assistant/learning/ls_abc123 \
  -H "Authorization: Bearer $TOKEN"
```

Response includes session details, signals found, proposals generated, and experiment results:

```json
{
    "success": true,
    "session": {
        "id": "ls_abc123",
        "status": "TESTING",
        "runCount": 100,
        "signals": [
            {
                "type": "LOW_SCORE",
                "severity": "high",
                "pattern": "Quality scores below 0.6 for research queries",
                "frequency": 23
            }
        ],
        "proposals": [
            {
                "id": "lp_def456",
                "title": "Improve handling of ambiguous queries",
                "riskTier": "LOW",
                "autoEligible": true
            }
        ],
        "experiments": [
            {
                "id": "le_ghi789",
                "status": "RUNNING",
                "progress": 0.64
            }
        ]
    }
}
```

## Learning Policy Configuration

Configure learning behavior per-agent via `LearningPolicy`:

```bash
curl -X PATCH https://agentc2.ai/agent/api/agents/research-assistant/learning/policy \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "enabled": true,
    "triggerMode": "threshold",
    "thresholds": {
      "signalCount": 5,
      "timeWindowMinutes": 60
    },
    "schedule": {
      "enabled": true,
      "cron": "0 */6 * * *"
    },
    "autoPromoteLowRisk": true,
    "requireApprovalForMediumRisk": true,
    "requireApprovalForHighRisk": true
  }'
```

### Policy Options

| Option                         | Description                            | Default                         |
| ------------------------------ | -------------------------------------- | ------------------------------- |
| `enabled`                      | Enable/disable continuous learning     | `true`                          |
| `triggerMode`                  | `"threshold"` or `"schedule"`          | `"threshold"`                   |
| `thresholds.signalCount`       | Minimum signals to trigger session     | `5`                             |
| `thresholds.timeWindowMinutes` | Time window for signal counting        | `60`                            |
| `schedule.cron`                | Cron expression for scheduled sessions | `"0 */6 * * *"` (every 6 hours) |
| `autoPromoteLowRisk`           | Auto-promote low-risk proposals        | `true`                          |
| `requireApprovalForMediumRisk` | Require approval for medium-risk       | `true`                          |
| `requireApprovalForHighRisk`   | Require approval for high-risk         | `true`                          |

## Best Practices

1. **Start with threshold-based triggers** — Let the system learn from real usage patterns before enabling scheduled sessions
2. **Review proposals before approval** — Even low-risk proposals benefit from human review to ensure they align with your goals
3. **Monitor experiment results** — Check that improvements are statistically significant and don't introduce regressions
4. **Use version control** — Create versions before learning sessions start to enable rollback if needed
5. **Set appropriate thresholds** — Balance sensitivity (catch issues early) with noise (avoid false positives)

<Callout type="tip">
    Learning sessions are resource-intensive. For agents with high run volumes, consider using
    scheduled sessions during off-peak hours rather than threshold-based triggers.
</Callout>

## Related Topics

- **[Evaluations](/docs/agents/evaluations)** — Learn how evaluation scorers measure agent performance
- **[Version Control](/docs/agents/version-control)** — Understand agent versioning and rollback capabilities
- **[Simulations](/docs/agents/simulations)** — Test agents against simulated scenarios before deployment
