---
title: "Model Providers"
description: "Compare OpenAI and Anthropic models for latency, cost, tool reliability, and context window."
section: "agents"
order: 4
primaryKeyword: "AI model providers comparison"
relatedSlugs: ["agents/configuration", "agents/budgets-and-costs"]
pageType: "reference"
---

# Model Providers

AgentC2 supports multiple AI model providers, with OpenAI and Anthropic as the primary options. Each provider offers different models optimized for speed, quality, reasoning, or cost.

## Supported providers

The platform currently supports:

- **OpenAI** — GPT-4o, GPT-4o-mini, o1, o3 (flagship, fast, reasoning models)
- **Anthropic** — Claude Sonnet 4, Claude Opus, Claude Haiku (high-quality, long-context models)
- **Google** — Gemini Pro, Gemini Flash (via Google AI SDK)
- **Groq** — Fast inference models (Llama, Mixtral)
- **Mistral** — Mistral Large, Mistral Small
- **xAI** — Grok models
- **DeepSeek** — DeepSeek models
- **Together AI** — Open-source model hosting
- **Fireworks** — Fast inference platform
- **OpenRouter** — Unified API for multiple providers
- **Kimi** — Long-context Chinese models

<Callout type="info">
    Model availability is dynamically fetched from provider APIs and cached for 1 hour. Models are
    filtered based on your organization's configured API keys.
</Callout>

## Model comparison

Compare models across key dimensions:

| Model                        | Provider  | Context Window | Input Cost (per 1M tokens) | Output Cost (per 1M tokens) | Tool Reliability     | Best For                      |
| ---------------------------- | --------- | -------------- | -------------------------- | --------------------------- | -------------------- | ----------------------------- |
| **gpt-4o**                   | OpenAI    | 128K           | $2.50                      | $10.00                      | ⭐⭐⭐⭐⭐ Excellent | General purpose, high quality |
| **gpt-4o-mini**              | OpenAI    | 128K           | $0.15                      | $0.60                       | ⭐⭐⭐⭐ Very good   | Cost-optimized, high volume   |
| **o1-preview**               | OpenAI    | 128K           | $15.00                     | $60.00                      | ⭐⭐⭐⭐⭐ Excellent | Complex reasoning, math       |
| **o3-mini**                  | OpenAI    | 128K           | $3.00                      | $12.00                      | ⭐⭐⭐⭐ Very good   | Fast reasoning                |
| **claude-sonnet-4-20250514** | Anthropic | 200K           | $3.00                      | $15.00                      | ⭐⭐⭐⭐⭐ Excellent | Long context, quality         |
| **claude-opus-4**            | Anthropic | 200K           | $15.00                     | $75.00                      | ⭐⭐⭐⭐⭐ Excellent | Highest quality               |
| **claude-haiku-3**           | Anthropic | 200K           | $0.25                      | $1.25                       | ⭐⭐⭐⭐ Very good   | Fast, cost-effective          |

### Cost notes

- Prices are approximate and may vary by region and volume discounts
- Input tokens include system instructions, user messages, and tool results
- Output tokens are the agent's generated responses
- Tool calls add to input tokens (tool results) and output tokens (tool invocations)

### Tool reliability

Tool reliability ratings reflect how consistently models:

- Choose appropriate tools for the task
- Format tool arguments correctly
- Handle tool errors gracefully
- Chain multiple tool calls effectively

All models support function calling, but GPT-4o and Claude Sonnet 4 show the best tool-use patterns in production.

## Switching providers

Change the provider and model by updating `modelProvider` and `modelName`:

```bash
curl -X PATCH https://agentc2.ai/agent/api/agents/research-assistant \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "modelProvider": "anthropic",
    "modelName": "claude-sonnet-4-20250514"
  }'
```

The change takes effect immediately. No code deployment required.

<Callout type="tip">
    You can A/B test different models by creating multiple agents with the same instructions but
    different models, then routing traffic between them.
</Callout>

## Provider-specific options

Each provider supports unique configuration options via `modelConfig`:

### OpenAI options

```json
{
    "modelConfig": {
        "toolChoice": "auto",
        "parallelToolCalls": true,
        "reasoningEffort": "medium"
    }
}
```

- **toolChoice**: `"auto"` (agent decides), `"required"` (must use tools), `"none"` (no tools)
- **parallelToolCalls**: `true` enables parallel tool execution (faster)
- **reasoningEffort**: For o1/o3 models: `"low"`, `"medium"`, `"high"` (depth vs speed)

### Anthropic options

```json
{
    "modelConfig": {
        "cacheControl": {
            "type": "ephemeral",
            "ttl": 3600
        }
    }
}
```

- **cacheControl**: Response caching to reduce costs
    - `type`: `"ephemeral"` (short-term) or `"long"` (persistent)
    - `ttl`: Time-to-live in seconds

## Model routing via API keys

The platform supports organization-scoped API keys for model routing:

1. **Organization-level keys** — Set in workspace settings, used for all agents in that org
2. **Environment-level keys** — Fallback to `OPENAI_API_KEY`, `ANTHROPIC_API_KEY` env vars
3. **Automatic selection** — The agent resolver uses the appropriate key based on request context

This enables:

- Multi-tenant isolation (each org uses its own API keys)
- Cost attribution per organization
- Different rate limits per tenant
- Compliance with data residency requirements

## How to choose

Select a model based on your priorities:

### Latency-sensitive → gpt-4o-mini

Best for: High-volume chat, real-time interactions, voice agents

```bash
{
  "modelProvider": "openai",
  "modelName": "gpt-4o-mini",
  "temperature": 0.7
}
```

- Fastest response times (~200-500ms)
- Lowest cost ($0.15/$0.60 per 1M tokens)
- Good tool reliability
- Suitable for most conversational use cases

### Quality-critical → claude-sonnet-4

Best for: Complex reasoning, long-form content, high-stakes decisions

```bash
{
  "modelProvider": "anthropic",
  "modelName": "claude-sonnet-4-20250514",
  "temperature": 0.3,
  "maxTokens": 8192
}
```

- Highest quality responses
- Long context window (200K tokens)
- Excellent tool use
- Best for research, analysis, content creation

### Cost-optimized → gpt-4o-mini or claude-haiku

Best for: High-volume, low-margin use cases

```bash
{
  "modelProvider": "openai",
  "modelName": "gpt-4o-mini"
}
```

or

```bash
{
  "modelProvider": "anthropic",
  "modelName": "claude-haiku-3"
}
```

- Both under $1 per 1M input tokens
- Fast inference
- Good enough quality for many use cases

### Complex reasoning → o1-preview or o3-mini

Best for: Math, code generation, multi-step problem solving

```bash
{
  "modelProvider": "openai",
  "modelName": "o1-preview",
  "modelConfig": {
    "reasoningEffort": "high"
  }
}
```

- Extended thinking mode
- Best for mathematical and logical reasoning
- Higher latency (5-30 seconds) but higher accuracy

## Listing available models

Query available models for a provider:

```bash
# List all OpenAI models
curl https://agentc2.ai/agent/api/models?provider=openai \
  -H "Authorization: Bearer $TOKEN"

# List all Anthropic models
curl https://agentc2.ai/agent/api/models?provider=anthropic \
  -H "Authorization: Bearer $TOKEN"

# List all models (all providers)
curl https://agentc2.ai/agent/api/models \
  -H "Authorization: Bearer $TOKEN"
```

Response format:

```json
{
    "success": true,
    "models": [
        {
            "provider": "openai",
            "name": "gpt-4o",
            "displayName": "GPT-4o",
            "category": "flagship",
            "contextWindow": 128000,
            "capabilities": {
                "chat": true,
                "vision": true,
                "tools": true
            },
            "pricing": {
                "inputCostPer1M": 2.5,
                "outputCostPer1M": 10.0
            }
        }
    ],
    "count": 15,
    "cached": true
}
```

## Cost optimization tips

1. **Use gpt-4o-mini for high volume** — 10x cheaper than gpt-4o with good quality
2. **Enable response caching** — Anthropic's cacheControl reduces costs for repeated queries
3. **Set maxTokens appropriately** — Don't request more tokens than needed
4. **Use parallel tool calls** — Reduces latency (fewer LLM calls) when multiple tools are needed
5. **Monitor token usage** — Track input/output tokens per run to identify optimization opportunities

## Related topics

- **[Agent Configuration](/docs/agents/configuration)** — Configure model settings, temperature, and tokens
- **[Budgets and Costs](/docs/agents/budgets-and-costs)** — Set spending limits and track usage
- **[Creating Agents](/docs/agents/creating-agents)** — Learn how to create agents with specific models
