---
title: "Architecture"
description: "Understand how AgentC2 processes requests, executes agents, and returns results."
section: "getting-started"
order: 3
primaryKeyword: "AI agent platform architecture"
secondaryKeywords: ["agent framework architecture", "platform overview"]
searchIntent: "informational"
pageType: "concept"
ctaLabel: "Launch AgentC2 Workspace"
ctaHref: "/workspace"
relatedSlugs: ["getting-started/key-concepts", "getting-started/introduction"]
---

# Architecture

AgentC2 is a managed platform for building, deploying, and orchestrating AI agents. This page explains how the system is organized from a user's perspective — how requests flow through the platform and how the major components interact.

## How you interact with AgentC2

There are three primary ways to work with the platform:

- **Workspace UI** — A web-based interface for building agents, running workflows, reviewing traces, and managing settings
- **REST API** — Programmatic access to all platform capabilities including agent execution, configuration, and metrics
- **MCP clients** — Connect external tools and IDEs to AgentC2 agents via the Model Context Protocol

## Request flow

When you send a message to an agent — whether from the UI, API, or an MCP client — the request follows this path:

<Steps>
    <Step title="Authenticate">
        The platform verifies your identity and resolves your organization and workspace context.
        API requests use bearer tokens; the UI uses session cookies.
    </Step>
    <Step title="Resolve agent">
        The agent definition is loaded from the platform, including its instructions, model
        configuration, attached tools, memory settings, and guardrails.
    </Step>
    <Step title="Execute">
        The agent calls the configured LLM (OpenAI or Anthropic), executes any tool calls (MCP
        integrations, native tools, or custom functions), and applies memory recall if enabled.
        Guardrails enforce input/output policies at each step.
    </Step>
    <Step title="Trace and evaluate">
        Every execution is recorded as a trace with step-level detail — LLM calls, tool executions,
        memory operations, and guardrail checks. Evaluation scorers run asynchronously to measure
        quality, safety, and relevance.
    </Step>
    <Step title="Return result">
        The response is streamed back to the caller. Token usage and cost are tracked for billing
        and budget enforcement.
    </Step>
</Steps>

## Core components

### Agent runtime

The agent runtime is responsible for loading agent definitions, orchestrating LLM calls, executing tools, and managing conversation memory. Agents are fully configuration-driven — you define behavior through the platform rather than writing code.

### Tool ecosystem

AgentC2 connects to external services through MCP (Model Context Protocol) servers and native integrations. Available tool categories include:

- **CRM** — HubSpot (contacts, companies, deals, pipeline)
- **Project management** — Jira (issues, sprints, tracking)
- **Communication** — Slack, Gmail, Microsoft Outlook
- **Web** — Firecrawl (scraping), Playwright (browser automation)
- **Productivity** — Google Drive, Dropbox, GitHub, Google Calendar
- **Automation** — Custom workflow triggers and webhooks

### Workflows and networks

Beyond single-agent execution, the platform supports **workflows** (multi-step orchestrations with branching, looping, and human approval gates) and **networks** (multi-agent systems where agents collaborate, delegate, and coordinate).

### Observability

Every agent run generates a complete trace. The platform provides dashboards for cost tracking, quality trends, performance metrics, and health scoring. See [Observability](/docs/platform/observability) for details.

### RAG pipeline

Documents can be ingested, chunked, embedded, and retrieved for context-augmented responses. Agents with RAG enabled automatically search relevant documents during execution.

## Multi-tenancy

All resources are scoped to organizations and workspaces. Tenant isolation is enforced at every layer — agents, documents, traces, and integrations are never shared across organization boundaries. See [Multi-Tenancy](/docs/platform/multi-tenancy) for the full model.

## Environment variables

When integrating with AgentC2 via API, the only credential you need is your **API token**, generated from the workspace settings page. All infrastructure configuration (LLM provider keys, database connections, MCP credentials) is managed by the platform.
