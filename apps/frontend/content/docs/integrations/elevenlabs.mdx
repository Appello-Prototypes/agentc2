---
title: "ElevenLabs"
description: "Connect agents to ElevenLabs for voice capabilities, text-to-speech, and conversational AI agents with tool invocation."
section: "integrations"
order: 13
primaryKeyword: "ElevenLabs voice integration"
relatedSlugs: ["integrations/overview", "agents/configuration"]
pageType: "how-to"
ctaLabel: "Explore Integrations in AgentC2"
ctaHref: "/workspace"
---

# ElevenLabs

ElevenLabs integration enables voice-enabled agents with premium text-to-speech quality, voice cloning, and conversational AI agents. Agents can generate natural-sounding speech, conduct voice conversations, and invoke tools during voice interactions.

## Overview

The ElevenLabs integration provides voice capabilities for agents, enabling them to speak responses aloud, conduct phone calls, and interact with users via voice interfaces. The integration supports both text-to-speech (TTS) for agent responses and conversational AI agents for real-time voice conversations with tool invocation.

<Callout type="info">
ElevenLabs integration supports both standalone TTS (for agent voice output) and conversational AI agents (for two-way voice conversations with MCP tool access).
</Callout>

## Prerequisites

- ElevenLabs account with API access
- API key from ElevenLabs dashboard
- Agent ID (for conversational AI agents)
- Webhook secret (for conversational AI webhooks)

## Setup

### Step 1: Get ElevenLabs API key

1. Log in to [ElevenLabs Dashboard](https://elevenlabs.io/app)
2. Navigate to **Profile** > **API Key**
3. Click **Copy API Key** or generate a new key
4. Save the key securely (starts with `sk_`)

### Step 2: Create conversational AI agent (optional)

For conversational AI agents with tool invocation:

1. Go to **Conversational AI** > **Agents**
2. Click **Create Agent**
3. Configure agent:
   - Name: "AgentC2 Assistant"
   - Voice: Select a voice
   - Instructions: Agent behavior instructions
4. Note the **Agent ID** (starts with `agent_`)

### Step 3: Configure webhook (for conversational AI)

1. In agent settings, go to **Tools** or **Webhooks**
2. Set webhook URL: `https://your-domain/agent/api/demos/live-agent-mcp/tools`
3. Generate webhook secret and copy it
4. Configure tools in ElevenLabs dashboard (see tool configuration below)

### Step 4: Configure in AgentC2

**Environment variables:**
```bash
ELEVENLABS_API_KEY="sk_..."
ELEVENLABS_AGENT_ID="agent_..." # For conversational AI
ELEVENLABS_WEBHOOK_SECRET="wsec_..." # For webhook authentication
ELEVENLABS_MCP_WEBHOOK_URL="https://your-domain/agent/api/demos/live-agent-mcp/tools"
```

**Via UI:**
1. Navigate to **Settings > Integrations**
2. Find **ElevenLabs** and configure:
   - API Key
   - Agent ID (if using conversational AI)
   - Webhook Secret (if using webhooks)
3. Test connection

**Via API:**
```bash
# Configure voice provider in agent
curl -X PATCH https://agentc2.ai/agent/api/agents/voice-assistant \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "voiceProvider": "elevenlabs",
    "voiceConfig": {
      "voiceId": "21m00Tcm4TlvDq8ikWAM",
      "model": "eleven_multilingual_v2"
    }
  }'
```

## Environment variables

| Variable | Required | Description |
|----------|----------|-------------|
| `ELEVENLABS_API_KEY` | Yes | ElevenLabs API key (format: `sk_...`) |
| `ELEVENLABS_AGENT_ID` | No | Conversational AI agent ID (format: `agent_...`) |
| `ELEVENLABS_WEBHOOK_SECRET` | No | Webhook authentication secret (format: `wsec_...`) |
| `ELEVENLABS_MCP_WEBHOOK_URL` | No | Webhook URL for tool invocation |

<Callout type="tip">
`ELEVENLABS_AGENT_ID` and webhook configuration are only needed for conversational AI agents with tool invocation. For standalone TTS, only `ELEVENLABS_API_KEY` is required.
</Callout>

## Voice capabilities

### Text-to-speech (TTS)

Generate speech from text:

```typescript
// Agent response is automatically converted to speech
const response = await agent.generate("What is the weather?");
// Response is streamed as audio using ElevenLabs TTS
```

Configure TTS in agent:

```bash
curl -X PATCH https://agentc2.ai/agent/api/agents/voice-assistant \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "voiceProvider": "elevenlabs",
    "voiceConfig": {
      "voiceId": "21m00Tcm4TlvDq8ikWAM",
      "model": "eleven_multilingual_v2",
      "stability": 0.5,
      "similarityBoost": 0.75
    }
  }'
```

### Voice quality settings

| Parameter | Range | Description |
|-----------|-------|-------------|
| `stability` | 0.0 - 1.0 | Voice stability (lower = more variation) |
| `similarityBoost` | 0.0 - 1.0 | Voice similarity to original (higher = more similar) |
| `style` | 0.0 - 1.0 | Style exaggeration (for certain voices) |
| `useSpeakerBoost` | boolean | Enhance speaker clarity |

### Available voices

ElevenLabs provides various voices:

- **Multilingual voices**: Support multiple languages
- **Cloned voices**: Custom voices created from samples
- **Premade voices**: Pre-configured voices (e.g., "Rachel", "Adam")

List available voices:

```bash
curl https://api.elevenlabs.io/v1/voices \
  -H "x-api-key: $ELEVENLABS_API_KEY"
```

## Conversational AI agents

### Tool invocation

ElevenLabs conversational AI agents can invoke MCP tools:

1. **Configure tools in ElevenLabs dashboard**:
   - Go to agent settings > **Tools**
   - Add tool: Webhook URL + Secret
   - Tool definitions are auto-discovered from AgentC2

2. **Tool execution flow**:
   ```
   User speaks → ElevenLabs agent → Determines tool needed
   → Calls AgentC2 webhook → AgentC2 executes MCP tool
   → Returns result → ElevenLabs agent → Speaks response
   ```

### Webhook configuration

Configure webhook endpoint in ElevenLabs:

```bash
# Get tool definitions for ElevenLabs
curl https://agentc2.ai/agent/api/demos/live-agent-mcp/tools-list?format=elevenlabs \
  -H "Authorization: Bearer $TOKEN"
```

Response format (ElevenLabs-compatible):

```json
{
  "tools": [
    {
      "name": "hubspot-get-contact",
      "description": "Get contact details from HubSpot",
      "parameters": {
        "type": "object",
        "properties": {
          "contactId": {
            "type": "string",
            "description": "HubSpot contact ID"
          }
        }
      },
      "url": "https://your-domain/agent/api/demos/live-agent-mcp/tools",
      "method": "POST",
      "headers": {
        "Authorization": "Bearer YOUR_WEBHOOK_SECRET"
      }
    }
  ]
}
```

### Webhook authentication

AgentC2 validates webhook requests:

```typescript
// Validate webhook secret
const webhookSecret = request.headers.get("Authorization");
if (webhookSecret !== `Bearer ${ELEVENLABS_WEBHOOK_SECRET}`) {
  return new Response("Unauthorized", { status: 401 });
}
```

## Common patterns

### Voice response generation

```typescript
// Agent generates text response
const textResponse = await agent.generate(userMessage);

// ElevenLabs TTS converts to speech
const audioStream = await elevenlabsTTS.generate(textResponse, {
  voiceId: "21m00Tcm4TlvDq8ikWAM",
  model: "eleven_multilingual_v2"
});

// Stream audio to user
return audioStream;
```

### Conversational AI with tools

```typescript
// User speaks: "What's John's email in HubSpot?"
// ElevenLabs agent determines tool needed
// Calls webhook:
POST /agent/api/demos/live-agent-mcp/tools
{
  "tool": "hubspot-get-contact",
  "arguments": { "contactId": "123" },
  "conversationId": "elevenlabs-conv-123"
}

// AgentC2 executes tool and returns result
// ElevenLabs agent speaks response
```

### Voice quality optimization

```typescript
// Optimize for clarity
{
  stability: 0.7, // More stable
  similarityBoost: 0.8, // More similar to original
  useSpeakerBoost: true // Enhance clarity
}

// Optimize for naturalness
{
  stability: 0.4, // More variation
  similarityBoost: 0.6, // Less strict similarity
  style: 0.3 // Slight style exaggeration
}
```

## Latency considerations

### TTS latency

ElevenLabs TTS latency:
- **First chunk**: ~200-500ms (connection + generation)
- **Subsequent chunks**: ~50-100ms (streaming)

Optimize for low latency:

```typescript
// Stream response as it's generated
const stream = await agent.generateStream(userMessage);
for await (const chunk of stream) {
  // Convert chunk to speech immediately
  const audioChunk = await elevenlabsTTS.generate(chunk);
  // Send to user
  sendAudioChunk(audioChunk);
}
```

### Tool invocation latency

Tool invocation adds latency:
- **Webhook call**: ~50-100ms
- **Tool execution**: Varies (HubSpot: ~200ms, Jira: ~300ms)
- **Response processing**: ~50ms

Total: ~300-450ms for simple tools

<Callout type="tip">
For voice interactions, keep tool calls simple and fast. Complex multi-step operations may feel slow in voice conversations.
</Callout>

## Troubleshooting

| Problem | Solution |
|---------|----------|
| **"Invalid API key"** | Verify `ELEVENLABS_API_KEY` is correct and not expired. Regenerate key in ElevenLabs dashboard if needed. |
| **"Voice not found"** | Check `voiceId` exists. List available voices via API and verify voice ID format. |
| **"Webhook authentication failed"** | Verify `ELEVENLABS_WEBHOOK_SECRET` matches ElevenLabs agent configuration. Check Authorization header format. |
| **"Tool execution timeout"** | Tool calls may timeout in voice context. Optimize tool execution or increase timeout limits. |
| **"Audio quality issues"** | Adjust `stability` and `similarityBoost` parameters. Try different voice models or enable `useSpeakerBoost`. |
| **"Rate limit exceeded"** | ElevenLabs limits API calls per tier. Upgrade plan or implement rate limiting/queuing. |

## Rate limiting

ElevenLabs API rate limits vary by plan:

- **Free tier**: Limited requests/month
- **Starter**: Higher limits
- **Creator/Pro**: Higher limits + priority

Monitor usage:

```bash
curl https://api.elevenlabs.io/v1/user \
  -H "x-api-key: $ELEVENLABS_API_KEY"
```

Response includes usage and limits.

## Best practices

### 1. Optimize for voice context

Keep responses concise for voice:

```typescript
// Text response: "Here are 5 items: 1. Item A, 2. Item B..."
// Voice response: "Here are 5 items. Item A, Item B..." (shorter)
```

### 2. Handle tool failures gracefully

In voice context, explain errors clearly:

```typescript
try {
  const result = await callTool("hubspot-get-contact", { contactId });
  return `Found contact: ${result.name}`;
} catch (error) {
  return "I couldn't find that contact. Could you check the contact ID?";
}
```

### 3. Use streaming for responsiveness

Stream audio as it's generated:

```typescript
// Don't wait for full response
const stream = agent.generateStream(message);
for await (const chunk of stream) {
  const audio = await elevenlabsTTS.generate(chunk);
  sendAudio(audio); // Send immediately
}
```

## Related topics

- **[Integrations Overview](/docs/integrations/overview)** — Learn about integration architecture
- **[Agent Configuration](/docs/agents/configuration)** — Configure voice providers
- **[Model Context Protocol](/docs/integrations/model-context-protocol)** — MCP tools for voice agents